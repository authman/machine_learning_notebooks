{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.plots import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on: 2018-02-28\n",
      "PyTorch version: 0.3.1.post2\n",
      "fastai version: 0.6\n"
     ]
    }
   ],
   "source": [
    "print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "get_cifar10(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_val(os.path.join(PATH, 'cifar10/train'), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sample(os.path.join(PATH, 'cifar10/train'), 0.01)\n",
    "create_sample(os.path.join(PATH, 'cifar10/valid'), 0.01)\n",
    "create_sample(os.path.join(PATH, 'cifar10/test'), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, bs, sample=False):\n",
    "    tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomFlip()], pad=sz//8, pad_mode=cv2.BORDER_CONSTANT)\n",
    "    return ImageClassifierData.from_paths(\n",
    "        f'{PATH}cifar10/',\n",
    "        trn_name='train' if not sample else 'train_sample',\n",
    "        val_name='valid' if not sample else 'valid_sample',\n",
    "        test_name='test'if not sample else 'train_sample',\n",
    "        tfms=tfms,\n",
    "        bs=bs,\n",
    "        test_with_labels=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "sample = False\n",
    "sz = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(sz, bs, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a notebook by fastai student [Karem Turgutlu](https://github.com/KeremTurgutlu/deeplearning/blob/master/Exploring%20Optimizers.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        for layer in self.layers:\n",
    "            l_x = layer(x)\n",
    "            x = F.relu(l_x)\n",
    "        return F.log_softmax(l_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(SimpleNet([32*32*3, 40, 10]), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Linear-1',\n",
       "              OrderedDict([('input_shape', [-1, 3072]),\n",
       "                           ('output_shape', [-1, 40]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 122920)])),\n",
       "             ('Linear-2',\n",
       "              OrderedDict([('input_shape', [-1, 40]),\n",
       "                           ('output_shape', [-1, 10]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 410)]))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SimpleNet(\n",
       "   (layers): ModuleList(\n",
       "     (0): Linear(in_features=3072, out_features=40, bias=True)\n",
       "     (1): Linear(in_features=40, out_features=10, bias=True)\n",
       "   )\n",
       " ), [122880, 40, 400, 10])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn, [o.numel() for o in learn.model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d85af71861940a0b1287e9a2ba0a870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 145/176 [00:10<00:02, 14.25it/s]"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a14572390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7320aea60124a388e53785d0bddfd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.815248   1.734034   0.394715  \n",
      "    1      1.715841   1.660614   0.409524        \n",
      "\n",
      "CPU times: user 36 s, sys: 15.2 s, total: 51.2 s\n",
      "Wall time: 25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.660614, 0.40952435731887815]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad4db3e2a964c5f87de26813f701037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.671294   1.641433   0.432468  \n",
      "    1      1.641768   1.603395   0.443474        \n",
      "\n",
      "CPU times: user 36.7 s, sys: 14.6 s, total: 51.3 s\n",
      "Wall time: 25.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6033955, 0.44347426593303679]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        layers.insert(0, 3)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(layers[i], layers[i+1], kernel_size=3, stride=2) for i in range(len(layers)-1)\n",
    "        ])\n",
    "        self.pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.l_out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return F.log_softmax(self.l_out(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvNet([20, 40, 80], 10), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Conv2d(3, 20, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): Conv2d(20, 40, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (2): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       "  (pool): AdaptiveMaxPool2d(output_size=1)\n",
       "  (l_out): Linear(in_features=80, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669332db98744c4489602e0017daa6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      2.337612   2.358285   0.097656  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69f86b6cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0d95f5328b40a59243cc6bfcc44b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/176 [00:00<?, ?it/s]> \u001b[0;32m<ipython-input-123-1e14f50e1920>\u001b[0m(18)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-85:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> F.log_softmax(self.l_out(x))\n",
      "Variable containing:\n",
      "-2.0491 -2.3645 -2.2452  ...  -2.3873 -2.4207 -2.4281\n",
      "-2.0622 -2.3444 -2.2073  ...  -2.3564 -2.4272 -2.4354\n",
      "-2.0566 -2.3867 -2.2242  ...  -2.3788 -2.3849 -2.3762\n",
      "          ...             ⋱             ...          \n",
      "-2.0760 -2.4041 -2.2687  ...  -2.4387 -2.3677 -2.4237\n",
      "-2.1147 -2.4470 -2.2184  ...  -2.3481 -2.3748 -2.3532\n",
      "-2.0542 -2.4162 -2.1944  ...  -2.3540 -2.3215 -2.3944\n",
      "[torch.cuda.FloatTensor of size 256x10 (GPU 0)]\n",
      "\n",
      "ipdb> \n",
      "Variable containing:\n",
      "-2.0491 -2.3645 -2.2452  ...  -2.3873 -2.4207 -2.4281\n",
      "-2.0622 -2.3444 -2.2073  ...  -2.3564 -2.4272 -2.4354\n",
      "-2.0566 -2.3867 -2.2242  ...  -2.3788 -2.3849 -2.3762\n",
      "          ...             ⋱             ...          \n",
      "-2.0760 -2.4041 -2.2687  ...  -2.4387 -2.3677 -2.4237\n",
      "-2.1147 -2.4470 -2.2184  ...  -2.3481 -2.3748 -2.3532\n",
      "-2.0542 -2.4162 -2.1944  ...  -2.3540 -2.3215 -2.3944\n",
      "[torch.cuda.FloatTensor of size 256x10 (GPU 0)]\n",
      "\n",
      "ipdb> F.log_softmax(self.l_out(x), dim=-1)\n",
      "Variable containing:\n",
      "-2.0491 -2.3645 -2.2452  ...  -2.3873 -2.4207 -2.4281\n",
      "-2.0622 -2.3444 -2.2073  ...  -2.3564 -2.4272 -2.4354\n",
      "-2.0566 -2.3867 -2.2242  ...  -2.3788 -2.3849 -2.3762\n",
      "          ...             ⋱             ...          \n",
      "-2.0760 -2.4041 -2.2687  ...  -2.4387 -2.3677 -2.4237\n",
      "-2.1147 -2.4470 -2.2184  ...  -2.3481 -2.3748 -2.3532\n",
      "-2.0542 -2.4162 -2.1944  ...  -2.3540 -2.3215 -2.3944\n",
      "[torch.cuda.FloatTensor of size 256x10 (GPU 0)]\n",
      "\n",
      "ipdb> exit\n",
      "\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-8c601a3d6b4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/superfast/machine_learning_notebooks/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/superfast/machine_learning_notebooks/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, use_clr, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle_len\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcycle_len\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n\u001b[0;32m--> 156\u001b[0;31m             metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, **kwargs)\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/superfast/machine_learning_notebooks/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, epochs, opt, crit, metrics, callbacks, stepper, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/superfast/machine_learning_notebooks/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-1e14f50e1920>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-1e14f50e1920>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.fit(1e-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ab380f33b64714b6b21ea48685df7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.370379   1.337397   0.521369  \n",
      "    1      1.308903   1.287841   0.543934        \n",
      "    2      1.2769     1.245464   0.556365        \n",
      "    3      1.230832   1.209976   0.573897        \n",
      "\n",
      "CPU times: user 1min 15s, sys: 29.4 s, total: 1min 44s\n",
      "Wall time: 51.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2099756, 0.57389705777168276]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-1, 4, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, ni, nf):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet2(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            ConvLayer(layers[i], layers[i+1]) for i in range(len(layers)-1)\n",
    "        ])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.conv_layers: x = layer(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.out(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvNet2([3, 20, 40, 80], 10), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d-1',\n",
       "              OrderedDict([('input_shape', [-1, 3, 32, 32]),\n",
       "                           ('output_shape', [-1, 20, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 560)])),\n",
       "             ('ConvLayer-2',\n",
       "              OrderedDict([('input_shape', [-1, 3, 32, 32]),\n",
       "                           ('output_shape', [-1, 20, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-3',\n",
       "              OrderedDict([('input_shape', [-1, 20, 16, 16]),\n",
       "                           ('output_shape', [-1, 40, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 7240)])),\n",
       "             ('ConvLayer-4',\n",
       "              OrderedDict([('input_shape', [-1, 20, 16, 16]),\n",
       "                           ('output_shape', [-1, 40, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-5',\n",
       "              OrderedDict([('input_shape', [-1, 40, 8, 8]),\n",
       "                           ('output_shape', [-1, 80, 4, 4]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 28880)])),\n",
       "             ('ConvLayer-6',\n",
       "              OrderedDict([('input_shape', [-1, 40, 8, 8]),\n",
       "                           ('output_shape', [-1, 80, 4, 4]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-7',\n",
       "              OrderedDict([('input_shape', [-1, 80]),\n",
       "                           ('output_shape', [-1, 10]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 810)]))])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ConvNet2(\n",
       "   (conv_layers): ModuleList(\n",
       "     (0): ConvLayer(\n",
       "       (conv): Conv2d(3, 20, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     )\n",
       "     (1): ConvLayer(\n",
       "       (conv): Conv2d(20, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     )\n",
       "     (2): ConvLayer(\n",
       "       (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "     )\n",
       "   )\n",
       "   (out): Linear(in_features=80, out_features=10, bias=True)\n",
       " ), 37490)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn, np.sum([o.numel() for o in learn.model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc59ab8fca34d45b7677c406e7ddfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.777986   1.63073    0.390039  \n",
      "    1      1.572971   1.525083   0.438557        \n",
      "\n",
      "CPU times: user 37.4 s, sys: 15.2 s, total: 52.6 s\n",
      "Wall time: 25.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5250833, 0.43855698555707934]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85def5081204f30bae89b74e2fcd240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.402017   1.373703   0.49776   \n",
      "    1      1.353078   1.309317   0.526746        \n",
      "\n",
      "CPU times: user 37.3 s, sys: 14.9 s, total: 52.2 s\n",
      "Wall time: 25.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3093166, 0.52674632370471952]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-1, 2, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size, stride, padding=1, bias=False)\n",
    "        self.a = nn.Parameter(torch.zeros(nf, 1, 1))\n",
    "        self.m = nn.Parameter(torch.ones(nf, 1, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x_chan = x.transpose(0, 1).contiguous().view(x.shape[1], -1)\n",
    "        if self.training:\n",
    "            self.means = x_chan.mean(1)[:, None, None]\n",
    "            self.stds = x_chan.std(1)[:, None, None]\n",
    "        return (x - self.means) / self.stds * self.m + self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5, padding=2)\n",
    "        self.layers = nn.ModuleList([BnLayer(layers[i], layers[i+1])\n",
    "            for i in range(len(layers)-1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        for l in self.layers: x = l(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.out(x)\n",
    "        return F.log_softmax(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvBnNet([10, 20, 40, 80, 160], 10), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89920b19be54dfe9a58673db2fab620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.589213   1.538288   0.446829  \n",
      "    1      1.393342   1.261483   0.552229        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2614827, 0.55222885906696317]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(3e-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c9e782b70f4b9699ebf5fc1def8a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.323952   1.220455   0.566705  \n",
      "    1      1.176521   1.061893   0.633375        \n",
      "    2      1.070975   0.964913   0.664809        \n",
      "    3      0.994748   0.907815   0.690591        \n",
      "\n",
      "CPU times: user 1min 17s, sys: 29.1 s, total: 1min 46s\n",
      "Wall time: 51.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.90781516, 0.69059053361415867]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-1, 4, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993d0e6ef54f4fea9614ee99c2647186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      0.90485    0.864697   0.699816  \n",
      "    1      0.890279   0.856413   0.707422        \n",
      "    2      0.869967   0.836291   0.712626        \n",
      "    3      0.854574   0.824421   0.71543         \n",
      "\n",
      "CPU times: user 1min 18s, sys: 29.9 s, total: 1min 48s\n",
      "Wall time: 52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.82442075, 0.71542968750000002]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 2, cycle_len=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnNet2(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5, padding=2)\n",
    "        self.layers1 = nn.ModuleList([BnLayer(layers[i], layers[i+1]) for i in range(len(layers) - 1)])\n",
    "        self.layers2 = nn.ModuleList([BnLayer(layers[i+1], layers[i+1], 1) for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        for l1, l2 in zip(self.layers1, self.layers2):\n",
    "            x = l1(x)\n",
    "            x = l2(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.out(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvBnNet2([10, 20, 40, 80, 160], 10), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b5eca490a541f58ce5cbc3bf0363cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.611595   1.547349   0.456032  \n",
      "    1      1.408553   1.324065   0.531376        \n",
      "\n",
      "CPU times: user 41.2 s, sys: 14.4 s, total: 55.6 s\n",
      "Wall time: 27.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3240651, 0.53137637972831731]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(3e-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7de22d84b14dd3872693b9eac9df7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.296573   1.149783   0.593302  \n",
      "    1      1.166588   1.037562   0.634444        \n",
      "    2      1.054883   0.948624   0.664993        \n",
      "    3      0.973495   0.870705   0.691992        \n",
      "\n",
      "CPU times: user 1min 22s, sys: 28.4 s, total: 1min 50s\n",
      "Wall time: 54.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.87070495, 0.69199218750000002]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-1, 4, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa12a94ec44420c93a4d6f207f395f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      0.896183   0.834289   0.698713  \n",
      "    1      0.861255   0.83438    0.700977        \n",
      "    2      0.848104   0.813686   0.707767        \n",
      "    3      0.827936   0.805872   0.713017        \n",
      "\n",
      "CPU times: user 1min 20s, sys: 29.2 s, total: 1min 50s\n",
      "Wall time: 54.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.80587196, 0.71301700472831731]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 2, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d-1',\n",
       "              OrderedDict([('input_shape', [-1, 3, 32, 32]),\n",
       "                           ('output_shape', [-1, 10, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 760)])),\n",
       "             ('Conv2d-2',\n",
       "              OrderedDict([('input_shape', [-1, 10, 32, 32]),\n",
       "                           ('output_shape', [-1, 20, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1800)])),\n",
       "             ('BnLayer-3',\n",
       "              OrderedDict([('input_shape', [-1, 10, 32, 32]),\n",
       "                           ('output_shape', [-1, 20, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-4',\n",
       "              OrderedDict([('input_shape', [-1, 20, 16, 16]),\n",
       "                           ('output_shape', [-1, 20, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 3600)])),\n",
       "             ('BnLayer-5',\n",
       "              OrderedDict([('input_shape', [-1, 20, 16, 16]),\n",
       "                           ('output_shape', [-1, 20, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-6',\n",
       "              OrderedDict([('input_shape', [-1, 20, 16, 16]),\n",
       "                           ('output_shape', [-1, 40, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 7200)])),\n",
       "             ('BnLayer-7',\n",
       "              OrderedDict([('input_shape', [-1, 20, 16, 16]),\n",
       "                           ('output_shape', [-1, 40, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-8',\n",
       "              OrderedDict([('input_shape', [-1, 40, 8, 8]),\n",
       "                           ('output_shape', [-1, 40, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 14400)])),\n",
       "             ('BnLayer-9',\n",
       "              OrderedDict([('input_shape', [-1, 40, 8, 8]),\n",
       "                           ('output_shape', [-1, 40, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-10',\n",
       "              OrderedDict([('input_shape', [-1, 40, 8, 8]),\n",
       "                           ('output_shape', [-1, 80, 4, 4]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 28800)])),\n",
       "             ('BnLayer-11',\n",
       "              OrderedDict([('input_shape', [-1, 40, 8, 8]),\n",
       "                           ('output_shape', [-1, 80, 4, 4]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-12',\n",
       "              OrderedDict([('input_shape', [-1, 80, 4, 4]),\n",
       "                           ('output_shape', [-1, 80, 4, 4]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 57600)])),\n",
       "             ('BnLayer-13',\n",
       "              OrderedDict([('input_shape', [-1, 80, 4, 4]),\n",
       "                           ('output_shape', [-1, 80, 4, 4]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-14',\n",
       "              OrderedDict([('input_shape', [-1, 80, 4, 4]),\n",
       "                           ('output_shape', [-1, 160, 2, 2]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 115200)])),\n",
       "             ('BnLayer-15',\n",
       "              OrderedDict([('input_shape', [-1, 80, 4, 4]),\n",
       "                           ('output_shape', [-1, 160, 2, 2]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-16',\n",
       "              OrderedDict([('input_shape', [-1, 160, 2, 2]),\n",
       "                           ('output_shape', [-1, 160, 2, 2]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 230400)])),\n",
       "             ('BnLayer-17',\n",
       "              OrderedDict([('input_shape', [-1, 160, 2, 2]),\n",
       "                           ('output_shape', [-1, 160, 2, 2]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-18',\n",
       "              OrderedDict([('input_shape', [-1, 160]),\n",
       "                           ('output_shape', [-1, 10]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1610)]))])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the resnet model as implemented in fastai lesson 7 [notebook](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson7-cifar10.ipynb). It is a really interesting version highlighting the key points while offering a slight simplification (we are not using shortcuts across blocks but have skip layer connections across individual layers, also not all layers have these - this way we don't have to worry about changes to dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetLayer(BnLayer):\n",
    "    def forward(self, x): return x + super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5, 1, padding=2)\n",
    "        self.layers1 = nn.ModuleList([BnLayer(layers[i], layers[i+1])\n",
    "            for i in range(len(layers)-1)])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1)\n",
    "            for i in range(len(layers)-1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i+1], 1)\n",
    "            for i in range(len(layers)-1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l1, l2, l3 in zip(self.layers1, self.layers2, self.layers3):\n",
    "            x = l3(l2(l1(x)))\n",
    "        x = F.adaptive_max_pool2d(x, 1).view(x.shape[0], -1)\n",
    "        x = self.out(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(Resnet([10, 20, 40, 80, 160], 10), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a80409ccee74295bb540de7af78fb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 51/176 [00:07<00:19,  6.49it/s]\n",
      " 30%|██▉       | 52/176 [00:07<00:19,  6.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-188:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.627015   1.5548     0.45378   \n",
      "    1      1.425162   1.335969   0.525356        \n",
      "\n",
      "CPU times: user 43.2 s, sys: 14.8 s, total: 58 s\n",
      "Wall time: 30.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3359692, 0.52535615861415863]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc7705a7b094f1592656d2cd351b053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.249886   1.186003   0.585099  \n",
      "    1      1.229403   1.142781   0.601068        \n",
      "    2      1.1027     1.07408    0.620738        \n",
      "    3      1.162429   1.10561    0.611121        \n",
      "    4      1.050975   1.002166   0.6473          \n",
      "    5      0.946638   0.917581   0.681204        \n",
      "    6      0.891561   0.912862   0.684972        \n",
      "\n",
      "CPU times: user 2min 31s, sys: 52.2 s, total: 3min 23s\n",
      "Wall time: 1min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.91286248, 0.68497242629528043]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 3, cycle_len=1, cycle_mult=2, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc53b2f2f6554a81bd32b06260440934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.010508   0.995416   0.657812  \n",
      "    1      0.903123   0.867581   0.697645        \n",
      "    2      0.817155   0.806663   0.721657        \n",
      "    3      0.775565   0.8035     0.720335        \n",
      "    4      0.865713   0.867063   0.696967        \n",
      "    5      0.795684   0.785423   0.729423        \n",
      "    6      0.706617   0.729066   0.750678        \n",
      "    7      0.66581    0.724963   0.751884        \n",
      "    8      0.768962   0.765685   0.734582        \n",
      "    9      0.703812   0.71644    0.750471        \n",
      "    10     0.627584   0.68053    0.767279        \n",
      "    11     0.593135   0.670861   0.77099         \n",
      "    12     0.707174   0.730261   0.749908        \n",
      "    13     0.628684   0.689788   0.765384        \n",
      "    14     0.566665   0.630109   0.780193        \n",
      "    15     0.516875   0.633232   0.783479        \n",
      "    16     0.632616   0.685618   0.769899        \n",
      "    17     0.58403    0.638131   0.783973        \n",
      "    18     0.515709   0.613479   0.797185        \n",
      "    19     0.481551   0.606473   0.798403        \n",
      "    20     0.594207   0.68396    0.767142        \n",
      "    21     0.530376   0.638067   0.782158        \n",
      "    22     0.475907   0.624927   0.789246        \n",
      "    23     0.435245   0.593156   0.797151        \n",
      "    24     0.546171   0.636611   0.78457         \n",
      "    25     0.501635   0.603047   0.795623        \n",
      "    26     0.435011   0.578724   0.803091        \n",
      "    27     0.400748   0.571203   0.807801        \n",
      "    28     0.517668   0.634863   0.7929          \n",
      "    29     0.46442    0.612594   0.798277        \n",
      "    30     0.408831   0.56681    0.810317        \n",
      "    31     0.369693   0.572903   0.80849         \n",
      "\n",
      "CPU times: user 11min 31s, sys: 4min, total: 15min 32s\n",
      "Wall time: 8min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.57290292, 0.80849034786224361]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 8, cycle_len=4, wds=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet 20 as in the original paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my take on the Resnet-20 from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) by Kaiming He et al. To confirm my understanding of the skip layer connections I looked at Yerlan Idelbayev's [implementation](https://github.com/akamaster/pytorch_resnet_cifar10)\n",
    "\n",
    "The paper mentions a result for a non resnet model of similar architecture, so building it is what I will start with. I should be able to train it to around 10% error rate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet20(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv_sz32 = nn.Sequential(\n",
    "            self.conv_block(16, 16),\n",
    "            self.conv_block(16, 16),\n",
    "            self.conv_block(16, 16),\n",
    "        )\n",
    "        self.bn_sz32 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv_sz16 = nn.Sequential(\n",
    "            self.conv_block(16, 32, 2),\n",
    "            self.conv_block(32, 32),\n",
    "            self.conv_block(32, 32),\n",
    "        )\n",
    "        self.bn_sz16 = nn.BatchNorm2d(32)\n",
    "                \n",
    "        self.conv_sz8 = nn.Sequential(\n",
    "            self.conv_block(32, 64, 2),\n",
    "            self.conv_block(64, 64),\n",
    "            self.conv_block(64, 64),\n",
    "        )\n",
    "        self.bn_sz8 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.conv_sz32(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn_sz32(x)\n",
    "        \n",
    "        x = self.conv_sz16(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn_sz16(x)\n",
    "        \n",
    "        x = self.conv_sz8(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn_sz8(x)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "    def conv_block(self, ni, no, initial_stride=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(ni, no, 3, padding=1, bias=False, stride=initial_stride),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(no),\n",
    "            nn.Conv2d(no, no, 3, padding=1, bias=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvNet20(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d-1',\n",
       "              OrderedDict([('input_shape', [-1, 3, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 432)])),\n",
       "             ('BatchNorm2d-2',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 32)])),\n",
       "             ('Conv2d-3',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 2304)])),\n",
       "             ('ReLU-4',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-5',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 32)])),\n",
       "             ('Conv2d-6',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 2304)])),\n",
       "             ('Conv2d-7',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 2304)])),\n",
       "             ('ReLU-8',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-9',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 32)])),\n",
       "             ('Conv2d-10',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 2304)])),\n",
       "             ('Conv2d-11',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 2304)])),\n",
       "             ('ReLU-12',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-13',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 32)])),\n",
       "             ('Conv2d-14',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 2304)])),\n",
       "             ('BatchNorm2d-15',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 32)])),\n",
       "             ('Conv2d-16',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 4608)])),\n",
       "             ('ReLU-17',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-18',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 64)])),\n",
       "             ('Conv2d-19',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 9216)])),\n",
       "             ('Conv2d-20',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 9216)])),\n",
       "             ('ReLU-21',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-22',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 64)])),\n",
       "             ('Conv2d-23',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 9216)])),\n",
       "             ('Conv2d-24',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 9216)])),\n",
       "             ('ReLU-25',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-26',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 64)])),\n",
       "             ('Conv2d-27',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 9216)])),\n",
       "             ('BatchNorm2d-28',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 32, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 64)])),\n",
       "             ('Conv2d-29',\n",
       "              OrderedDict([('input_shape', [-1, 32, 16, 16]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 18432)])),\n",
       "             ('ReLU-30',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-31',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 128)])),\n",
       "             ('Conv2d-32',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('Conv2d-33',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('ReLU-34',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-35',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 128)])),\n",
       "             ('Conv2d-36',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('Conv2d-37',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('ReLU-38',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-39',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 128)])),\n",
       "             ('Conv2d-40',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 36864)])),\n",
       "             ('BatchNorm2d-41',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 128)])),\n",
       "             ('AdaptiveAvgPool2d-42',\n",
       "              OrderedDict([('input_shape', [-1, 64, 8, 8]),\n",
       "                           ('output_shape', [-1, 64, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-43',\n",
       "              OrderedDict([('input_shape', [-1, 64]),\n",
       "                           ('output_shape', [-1, 10]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 650)]))])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269274"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([o.numel() for o in learn.model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b2896b42a44763ac20125f54415571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=91), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 87/176 [00:07<00:07, 11.61it/s]\n",
      " 51%|█████     | 89/176 [00:07<00:07, 11.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-335:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/radek/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.764424   1.807509   0.337718  \n",
      "    1      1.58097    1.624343   0.407778        \n",
      "    2      1.450453   1.516669   0.462155        \n",
      "    3      1.340899   1.314045   0.533996        \n",
      "    4      1.217976   1.281944   0.542682        \n",
      "    5      1.125525   1.196676   0.554205        \n",
      "    6      1.029373   1.204094   0.587293        \n",
      "    7      0.952631   0.984959   0.647587        \n",
      "    8      0.894612   1.03252    0.642142        \n",
      "    9      0.858335   0.867485   0.697852        \n",
      "    10     0.79606    0.850154   0.715464        \n",
      "    11     0.755315   0.934716   0.683548        \n",
      "    12     0.719865   0.796178   0.728068        \n",
      "    13     0.689435   0.796086   0.733536        \n",
      "    14     0.668266   0.757817   0.738798        \n",
      "    15     0.644604   0.746039   0.743405        \n",
      "    16     0.63301    0.671269   0.776379        \n",
      "    17     0.596379   0.753812   0.750931        \n",
      "    18     0.580103   0.640953   0.782767        \n",
      "    19     0.568194   0.622492   0.792567        \n",
      "    20     0.559508   0.626143   0.783444        \n",
      "    21     0.53918    0.549855   0.811661        \n",
      "    22     0.537884   0.64159    0.782583        \n",
      "    23     0.524609   0.577813   0.805113        \n",
      "    24     0.521455   0.572785   0.807904        \n",
      "    25     0.510983   0.610589   0.797863        \n",
      "    26     0.483488   0.615007   0.795692        \n",
      "    27     0.480844   0.531624   0.818509        \n",
      "    28     0.477835   0.54848    0.805136        \n",
      "    29     0.464186   0.592355   0.804619        \n",
      "    30     0.462166   0.599571   0.79591         \n",
      "    31     0.461111   0.553147   0.818589        \n",
      "    32     0.457874   0.585879   0.804216        \n",
      "    33     0.439465   0.606048   0.801838        \n",
      "    34     0.435117   0.534276   0.823415        \n",
      "    35     0.434264   0.487796   0.840924        \n",
      "    36     0.433135   0.526082   0.827114        \n",
      "    37     0.420933   0.582774   0.816636        \n",
      "    38     0.421694   0.514803   0.83071         \n",
      "    39     0.40681    0.494403   0.836926        \n",
      "    40     0.405179   0.462171   0.845795        \n",
      "    41     0.40478    0.572124   0.818739        \n",
      "    42     0.398174   0.512102   0.831445        \n",
      "    43     0.399424   0.489836   0.831721        \n",
      "    44     0.393798   0.508139   0.832273        \n",
      "    45     0.393826   0.472268   0.844416        \n",
      "    46     0.386225   0.468842   0.843773        \n",
      "    47     0.383745   0.480104   0.844738        \n",
      "    48     0.378503   0.463876   0.844738        \n",
      "    49     0.37584    0.45131    0.849173        \n",
      "    50     0.371608   0.697583   0.781905        \n",
      "    51     0.36845    0.482502   0.84321         \n",
      "    52     0.378633   0.555579   0.830331        \n",
      "    53     0.354236   0.527683   0.836305        \n",
      "    54     0.358251   0.478313   0.846415        \n",
      "    55     0.355906   0.527415   0.825253        \n",
      "    56     0.35396    0.451528   0.854814        \n",
      "    57     0.35836    0.515407   0.831457        \n",
      "    58     0.35349    0.444512   0.852137        \n",
      "    59     0.341882   0.458023   0.854768        \n",
      "    60     0.348087   0.513466   0.839522        \n",
      "    61     0.335517   0.473894   0.844324        \n",
      "    62     0.339292   0.495541   0.844956        \n",
      "    63     0.338069   0.445149   0.853274        \n",
      "    64     0.326829   0.517622   0.835214        \n",
      "    65     0.335146   0.454362   0.850689        \n",
      "    66     0.326877   0.488175   0.84205         \n",
      "    67     0.314628   0.459999   0.847668        \n",
      "    68     0.325895   0.447388   0.855607        \n",
      "    69     0.319565   0.528481   0.840751        \n",
      "    70     0.322291   0.438243   0.860041        \n",
      "    71     0.311641   0.489434   0.846886        \n",
      "    72     0.319257   0.463506   0.847989        \n",
      "    73     0.323198   0.438136   0.860903        \n",
      "    74     0.307644   0.526227   0.840614        \n",
      "    75     0.315474   0.452314   0.852459        \n",
      "    76     0.323428   0.452396   0.85417         \n",
      "    77     0.309105   0.488926   0.847484        \n",
      "    78     0.307221   0.448177   0.859605        \n",
      "    79     0.302101   0.439044   0.859398        \n",
      "    80     0.301866   0.462667   0.852401        \n",
      "    81     0.303753   0.475296   0.855032        \n",
      "    82     0.302576   0.473453   0.845565        \n",
      "    83     0.30362    0.47149    0.85278         \n",
      "    84     0.303985   0.486474   0.849506        \n",
      "    85     0.300602   0.449292   0.856744        \n",
      "    86     0.302938   0.536817   0.831147        \n",
      "    87     0.291983   0.506725   0.841441        \n",
      "    88     0.294942   0.461624   0.851723        \n",
      "    89     0.290838   0.416661   0.868497        \n",
      "    90     0.294156   0.469368   0.852378        \n",
      "\n",
      "CPU times: user 29min 57s, sys: 11min 12s, total: 41min 9s\n",
      "Wall time: 20min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46936798, 0.85237821638584133]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(0.1, 91, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f601f7c18d54cdfa9e1b2e65f5cd434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=45), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      0.197255   0.340206   0.889832  \n",
      "    1      0.177336   0.341679   0.889292        \n",
      "    2      0.170184   0.343211   0.890051        \n",
      "    3      0.164205   0.348146   0.888534        \n",
      "    4      0.15454    0.351982   0.88912         \n",
      "    5      0.153716   0.34671    0.886018        \n",
      "    6      0.149854   0.350465   0.889315        \n",
      "    7      0.145639   0.348143   0.89105         \n",
      "    8      0.148226   0.350342   0.889637        \n",
      "    9      0.139488   0.354603   0.889901        \n",
      "    10     0.137389   0.355831   0.888557        \n",
      "    11     0.141085   0.361287   0.88966         \n",
      "    12     0.129815   0.359175   0.890947        \n",
      "    13     0.131471   0.364987   0.890901        \n",
      "    14     0.12708    0.364369   0.890361        \n",
      "    15     0.128731   0.360671   0.888534        \n",
      "    16     0.125278   0.375008   0.884846        \n",
      "    17     0.130269   0.370258   0.88704         \n",
      "    18     0.122487   0.377815   0.889269        \n",
      "    19     0.125376   0.371474   0.888879        \n",
      "    20     0.122667   0.379013   0.889878        \n",
      "    21     0.118276   0.376245   0.888293        \n",
      "    22     0.11856    0.389261   0.887121        \n",
      "    23     0.123036   0.385309   0.889465        \n",
      "    24     0.114367   0.382355   0.889246        \n",
      "    25     0.115254   0.385065   0.887408        \n",
      "    26     0.117283   0.394089   0.885995        \n",
      "    27     0.114585   0.397074   0.885558        \n",
      "    28     0.11211    0.392839   0.88773         \n",
      "    29     0.114019   0.39301    0.885949        \n",
      "    30     0.111261   0.408027   0.88287         \n",
      "    31     0.108396   0.402091   0.88758         \n",
      "    32     0.106882   0.407537   0.8858          \n",
      "    33     0.106553   0.403537   0.884409        \n",
      "    34     0.109489   0.41255    0.884409        \n",
      "    35     0.10754    0.417672   0.88233         \n",
      "    36     0.107088   0.412239   0.885581        \n",
      "    37     0.10338    0.416851   0.884019        \n",
      "    38     0.104978   0.416497   0.885512        \n",
      "    39     0.102632   0.415059   0.88673         \n",
      "    40     0.105841   0.419385   0.883628        \n",
      "    41     0.102124   0.415386   0.886144        \n",
      "    42     0.101012   0.421019   0.886558        \n",
      "    43     0.103813   0.416763   0.884432        \n",
      "    44     0.095107   0.426603   0.882629        \n",
      "\n",
      "CPU times: user 14min 49s, sys: 5min 31s, total: 20min 20s\n",
      "Wall time: 10min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42660308, 0.88262867629528041]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 45, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e14cafd94054a4d9b1407e86e45d7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=45), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      0.091542   0.416091   0.88619   \n",
      "    1      0.086538   0.416331   0.887362        \n",
      "    2      0.084004   0.419459   0.884628        \n",
      "    3      0.084365   0.412448   0.887948        \n",
      "    4      0.08233    0.41294    0.888534        \n",
      "    5      0.083735   0.415354   0.888339        \n",
      "    6      0.083106   0.416497   0.88619         \n",
      "    7      0.083616   0.414971   0.887557        \n",
      "    8      0.080715   0.414318   0.885604        \n",
      "    9      0.082281   0.419471   0.887339        \n",
      "    10     0.080764   0.418656   0.888534        \n",
      "    11     0.082339   0.420051   0.886386        \n",
      "    12     0.079347   0.419791   0.890487        \n",
      "    13     0.0807     0.418792   0.887362        \n",
      "    14     0.083549   0.419302   0.887167        \n",
      "    15     0.081056   0.421359   0.887144        \n",
      "    16     0.07909    0.420373   0.8858          \n",
      "    17     0.076888   0.420996   0.885214        \n",
      "    18     0.082005   0.420781   0.885972        \n",
      "    19     0.080335   0.423926   0.885995        \n",
      "    20     0.080722   0.423555   0.886581        \n",
      "    21     0.078076   0.4222     0.886972        \n",
      "    22     0.082217   0.42613    0.885777        \n",
      "    23     0.081848   0.421634   0.886386        \n",
      "    24     0.07482    0.42579    0.887362        \n",
      "    25     0.081518   0.42569    0.886753        \n",
      "    26     0.081067   0.426199   0.884823        \n",
      "    27     0.079892   0.426603   0.886363        \n",
      "    28     0.076334   0.429178   0.887534        \n",
      "    29     0.079196   0.428156   0.886949        \n",
      "    30     0.081883   0.424885   0.887339        \n",
      "    31     0.07936    0.426367   0.887753        \n",
      "    32     0.078179   0.426831   0.887534        \n",
      "    33     0.076926   0.42986    0.88773         \n",
      "    34     0.076245   0.427524   0.886167        \n",
      "    35     0.078648   0.431871   0.887167        \n",
      "    36     0.075359   0.430583   0.885581        \n",
      "    37     0.077168   0.432375   0.886386        \n",
      "    38     0.074375   0.433832   0.885777        \n",
      "    39     0.074513   0.430801   0.885823        \n",
      "    40     0.07636    0.42733    0.886604        \n",
      "    41     0.076063   0.428241   0.885604        \n",
      "    42     0.074324   0.429493   0.88773         \n",
      "    43     0.075739   0.435196   0.885777        \n",
      "    44     0.076936   0.43122    0.886167        \n",
      "\n",
      "CPU times: user 14min 49s, sys: 5min 30s, total: 20min 20s\n",
      "Wall time: 10min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43122029, 0.88616727888584135]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-3, 45, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('conv_net_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8871"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np(*learn.predict_with_targs(is_test=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90110000000000001"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_preds,y = learn.TTA(is_test=True)\n",
    "preds = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(preds,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper reports test error of just under 10% without TTA so the results are in the correct ballpark. The number of parameters also seems okay.\n",
    "\n",
    "Moving onto Resnet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, ni, no):\n",
    "        super().__init__()\n",
    "        initial_stride = 1 if ni == no else 2\n",
    "        self.conv1 = nn.Conv2d(ni, no, 3, padding=1, bias=False, stride=initial_stride)\n",
    "        self.bn1 = nn.BatchNorm2d(no)\n",
    "        self.conv2 = nn.Conv2d(no, no, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(no)\n",
    "        self.shortcut = self.get_shortcut(ni, no)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.bn1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.bn2(out)\n",
    "        return out\n",
    "\n",
    "    def get_shortcut(self, ni, no):\n",
    "        if ni == no: return lambda x: x\n",
    "        return lambda x: F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, no//4, no//4), \"constant\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet20(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv_sz32 = nn.Sequential(\n",
    "            ConvBlock(16, 16),\n",
    "            ConvBlock(16, 16),\n",
    "            ConvBlock(16, 16),\n",
    "        )\n",
    "        \n",
    "        self.conv_sz16 = nn.Sequential(\n",
    "            ConvBlock(16, 32),\n",
    "            ConvBlock(32, 32),\n",
    "            ConvBlock(32, 32),\n",
    "        )\n",
    "                \n",
    "        self.conv_sz8 = nn.Sequential(\n",
    "            ConvBlock(32, 64),\n",
    "            ConvBlock(64, 64),\n",
    "            ConvBlock(64, 64),\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.conv_sz32(x)\n",
    "        x = self.conv_sz16(x)\n",
    "        x = self.conv_sz8(x)\n",
    "        \n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "    def conv_block(self, ni, no, initial_stride=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(ni, no, 3, padding=1, bias=False, stride=initial_stride),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(no),\n",
    "            nn.Conv2d(no, no, 3, padding=1, bias=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(Resnet20(), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269722"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([o.numel() for o in learn.model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64819a9154d44a3380fbf65ca6c0c091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=91), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      1.475456   1.512915   0.461834  \n",
      "    1      1.134402   1.192573   0.586615        \n",
      "    2      0.961062   1.11166    0.61736         \n",
      "    3      0.82719    0.847379   0.708284        \n",
      "    4      0.728611   0.870132   0.703688        \n",
      "    5      0.68552    0.72559    0.749138        \n",
      "    6      0.624721   0.737766   0.746082        \n",
      "    7      0.578274   0.642062   0.776585        \n",
      "    8      0.554314   0.652344   0.777734        \n",
      "    9      0.507382   0.627087   0.791831        \n",
      "    10     0.491715   0.604422   0.79923         \n",
      "    11     0.480068   0.594764   0.79884         \n",
      "    12     0.465572   0.695039   0.768784        \n",
      "    13     0.446349   0.537606   0.817371        \n",
      "    14     0.428138   0.537791   0.818888        \n",
      "    15     0.41319    0.57453    0.809777        \n",
      "    16     0.404278   0.543117   0.819864        \n",
      "    17     0.388414   0.505009   0.834605        \n",
      "    18     0.381639   0.502924   0.834616        \n",
      "    19     0.37637    0.563413   0.816004        \n",
      "    20     0.365316   0.534191   0.818095        \n",
      "    21     0.363628   0.482927   0.845738        \n",
      "    22     0.346741   0.497742   0.836903        \n",
      "    23     0.333504   0.49155    0.836477        \n",
      "    24     0.322114   0.469136   0.845933        \n",
      "    25     0.328589   0.488551   0.839419        \n",
      "    26     0.309487   0.492936   0.837684        \n",
      "    27     0.311747   0.437249   0.850735        \n",
      "    28     0.304564   0.518595   0.837891        \n",
      "    29     0.302633   0.521173   0.836558        \n",
      "    30     0.289874   0.465372   0.85116         \n",
      "    31     0.294389   0.504124   0.838235        \n",
      "    32     0.286343   0.497147   0.849092        \n",
      "    33     0.273609   0.488514   0.842865        \n",
      "    34     0.276162   0.514232   0.840142        \n",
      "    35     0.260952   0.47397    0.854848        \n",
      "    36     0.273978   0.476989   0.859949        \n",
      "    37     0.267265   0.467471   0.850356        \n",
      "    38     0.257934   0.462068   0.854653        \n",
      "    39     0.259184   0.436923   0.858835        \n",
      "    40     0.243521   0.47612    0.851126        \n",
      "    41     0.246853   0.496066   0.854837        \n",
      "    42     0.240081   0.436413   0.864717        \n",
      "    43     0.251978   0.445879   0.865556        \n",
      "    44     0.234236   0.448562   0.862868        \n",
      "    45     0.240472   0.486504   0.847082        \n",
      "    46     0.235452   0.479456   0.850253        \n",
      "    47     0.235561   0.446298   0.863856        \n",
      "    48     0.233518   0.491397   0.853619        \n",
      "    49     0.22147    0.477298   0.859984        \n",
      "    50     0.230026   0.418693   0.86628         \n",
      "    51     0.227109   0.48079    0.845071        \n",
      "    52     0.220377   0.480565   0.854297        \n",
      "    53     0.216631   0.436873   0.870209        \n",
      "    54     0.22041    0.427862   0.865005        \n",
      "    55     0.219397   0.483182   0.855733        \n",
      "    56     0.213713   0.41503    0.866441        \n",
      "    57     0.208725   0.518393   0.843693        \n",
      "    58     0.211431   0.454491   0.865591        \n",
      "    59     0.219124   0.510161   0.844301        \n",
      "    60     0.20589    0.425284   0.86651         \n",
      "    61     0.200392   0.449392   0.85687         \n",
      "    62     0.207687   0.458409   0.862845        \n",
      "    63     0.203551   0.458527   0.866912        \n",
      "    64     0.195709   0.48899    0.858272        \n",
      "    65     0.200106   0.379281   0.876746        \n",
      "    66     0.198039   0.435539   0.869003        \n",
      "    67     0.198133   0.465013   0.853355        \n",
      "    68     0.194066   0.536633   0.84529         \n",
      "    69     0.203846   0.478737   0.860926        \n",
      "    70     0.192766   0.435204   0.864591        \n",
      "    71     0.185632   0.462822   0.865545        \n",
      "    72     0.195623   0.468713   0.860145        \n",
      "    73     0.19527    0.411695   0.878631        \n",
      "    74     0.18221    0.453388   0.865809        \n",
      "    75     0.186623   0.488891   0.859858        \n",
      "    76     0.177823   0.474799   0.862201        \n",
      "    77     0.186005   0.511925   0.849552        \n",
      "    78     0.18277    0.46353    0.866716        \n",
      "    79     0.182827   0.494374   0.863741        \n",
      "    80     0.180013   0.446447   0.864591        \n",
      "    81     0.182604   0.495138   0.858812        \n",
      "    82     0.184548   0.438205   0.868888        \n",
      "    83     0.187314   0.436978   0.86705         \n",
      "    84     0.179475   0.560273   0.847932        \n",
      "    85     0.176764   0.486456   0.866314        \n",
      "    86     0.175883   0.448291   0.869738        \n",
      "    87     0.18069    0.457928   0.866762        \n",
      "    88     0.175488   0.495789   0.850506        \n",
      "    89     0.174368   0.501935   0.859283        \n",
      "    90     0.171674   0.442953   0.874724        \n",
      "\n",
      "CPU times: user 31min 11s, sys: 11min 42s, total: 42min 54s\n",
      "Wall time: 21min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44295287, 0.87472426593303676]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(0.1, 91, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833cae7b60ee48409ed7048d26394b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=45), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      0.097369   0.346058   0.894933  \n",
      "    1      0.079873   0.3498     0.894715        \n",
      "    2      0.070254   0.347406   0.898771        \n",
      "    3      0.066711   0.352402   0.898254        \n",
      "    4      0.065342   0.355267   0.898817        \n",
      "    5      0.057232   0.36067    0.89977         \n",
      "    6      0.056776   0.356819   0.899793        \n",
      "    7      0.056349   0.358762   0.901942        \n",
      "    8      0.052319   0.360658   0.899403        \n",
      "    9      0.050146   0.365653   0.899793        \n",
      "    10     0.04673    0.367425   0.89923         \n",
      "    11     0.044902   0.369169   0.901183        \n",
      "    12     0.042939   0.379125   0.89938         \n",
      "    13     0.040126   0.375541   0.900965        \n",
      "    14     0.04206    0.378844   0.900333        \n",
      "    15     0.040503   0.379802   0.902114        \n",
      "    16     0.039588   0.379281   0.902677        \n",
      "    17     0.039253   0.387088   0.900207        \n",
      "    18     0.037465   0.388607   0.900161        \n",
      "    19     0.037338   0.388299   0.901896        \n",
      "    20     0.037462   0.389463   0.903458        \n",
      "    21     0.035555   0.388067   0.900184        \n",
      "    22     0.035556   0.395809   0.902091        \n",
      "    23     0.030644   0.398168   0.899357        \n",
      "    24     0.035678   0.400884   0.900724        \n",
      "    25     0.031047   0.402098   0.904262        \n",
      "    26     0.031045   0.398727   0.901137        \n",
      "    27     0.029204   0.398264   0.902872        \n",
      "    28     0.029179   0.401922   0.901333        \n",
      "    29     0.027691   0.411546   0.899575        \n",
      "    30     0.028822   0.408261   0.902505        \n",
      "    31     0.027366   0.406726   0.905239        \n",
      "    32     0.025607   0.409224   0.902895        \n",
      "    33     0.028139   0.410743   0.900574        \n",
      "    34     0.026634   0.419506   0.902137        \n",
      "    35     0.027017   0.415337   0.902482        \n",
      "    36     0.025152   0.418149   0.900551        \n",
      "    37     0.024619   0.410403   0.904067        \n",
      "    38     0.025222   0.413252   0.900333        \n",
      "    39     0.022895   0.419196   0.9027          \n",
      "    40     0.02512    0.41684    0.901137        \n",
      "    41     0.023837   0.422401   0.902482        \n",
      "    42     0.022415   0.426887   0.900919        \n",
      "    43     0.021034   0.430818   0.899943        \n",
      "    44     0.022519   0.429873   0.903091        \n",
      "\n",
      "CPU times: user 15min 16s, sys: 5min 47s, total: 21min 4s\n",
      "Wall time: 10min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42987329, 0.90309053361415859]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 45, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2f569a892a43c5ad0b9ddbfe9dd6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=45), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy        \n",
      "    0      0.02101    0.430785   0.901333  \n",
      "    1      0.019884   0.429129   0.902918        \n",
      "    2      0.021076   0.43082    0.901746        \n",
      "    3      0.018727   0.43232    0.901942        \n",
      "    4      0.020237   0.431528   0.901505        \n",
      "    5      0.01909    0.432533   0.9027          \n",
      "    6      0.019231   0.42905    0.902505        \n",
      "    7      0.018246   0.43302    0.902114        \n",
      "    8      0.019312   0.430881   0.902677        \n",
      "    9      0.019577   0.432589   0.903286        \n",
      "    10     0.017716   0.430369   0.901919        \n",
      "    11     0.018432   0.430812   0.901137        \n",
      "    12     0.018933   0.435835   0.902895        \n",
      "    13     0.018108   0.432159   0.903091        \n",
      "    14     0.018306   0.42867    0.902895        \n",
      "    15     0.018919   0.430392   0.901919        \n",
      "    16     0.017968   0.431169   0.902677        \n",
      "    17     0.017605   0.430533   0.901723        \n",
      "    18     0.018116   0.430775   0.9027          \n",
      "    19     0.016258   0.429925   0.901528        \n",
      "    20     0.018028   0.429743   0.902309        \n",
      "    21     0.016645   0.429258   0.904044        \n",
      "    22     0.017334   0.430265   0.9027          \n",
      "    23     0.017029   0.433369   0.901723        \n",
      "    24     0.018146   0.430531   0.902114        \n",
      "    25     0.017699   0.428543   0.902114        \n",
      "    26     0.018555   0.433406   0.903091        \n",
      "    27     0.016767   0.431393   0.90131         \n",
      "    28     0.016956   0.432734   0.902091        \n",
      "    29     0.015909   0.431722   0.901505        \n",
      "    30     0.017048   0.434481   0.901505        \n",
      "    31     0.018031   0.429365   0.9027          \n",
      "    32     0.016998   0.430591   0.901723        \n",
      "    33     0.016219   0.431848   0.902895        \n",
      "    34     0.016929   0.435159   0.900551        \n",
      "    35     0.016125   0.433334   0.901137        \n",
      "    36     0.0167     0.4324     0.900551        \n",
      "    37     0.016102   0.437312   0.901723        \n",
      "    38     0.01675    0.437494   0.900161        \n",
      "    39     0.01702    0.437078   0.901919        \n",
      "    40     0.016737   0.436319   0.90131         \n",
      "    41     0.017269   0.435995   0.901551        \n",
      "    42     0.017619   0.435141   0.901505        \n",
      "    43     0.016901   0.43734    0.900965        \n",
      "    44     0.017869   0.43411    0.899012        \n",
      "\n",
      "CPU times: user 15min 14s, sys: 5min 46s, total: 21min 1s\n",
      "Wall time: 10min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4341104, 0.89901194870471957]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-3, 45, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnet_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90510000000000002"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np(*learn.predict_with_targs(is_test=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91639999999999999"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_preds,y = learn.TTA(is_test=True)\n",
    "preds = np.mean(np.exp(log_preds),0)\n",
    "accuracy_np(preds,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is overfitting qutie severly. The difference between my implementation and what I believe was done in the paper is where I put batch norm. In the paper batch norm is likely placed before relu and I place it after.\n",
    "\n",
    "This could account for the discrepancy in performance. Or I could have gotten particularly unlucky on the training. No point reading too much into this without further experimentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
